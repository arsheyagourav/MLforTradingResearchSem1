{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ccd1bc-42f0-4ce9-aac0-212696931e4b",
   "metadata": {},
   "source": [
    "article-to-pr-mapper:\n",
    "Has around 900,000 entries. Includes URL (should also be in jsonl), Title, Target URL (map to press release), date first seen, company name, and news url domain. A very large portion of the entries are missing titles. Appears to be at least 1/4th of the entries. Then at a certian point there are no titles at all. But the other columns are filled out. Additionally, some of the titles are not very informative. For example, there are hundreds of entries with the title \"Search - Business Insider\". The main issue with this dataset appears to be the titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03a200-fa7b-418c-b942-c9c0325bfb9c",
   "metadata": {},
   "source": [
    "Full-source-scored-data.jsonl:\n",
    "This file includes strings titled article_url, Each article also has \"links\" which is a loarge list of dictionaries with href, text, and char_start_idx. There is target_timestamp (float) which appears to be in milliseconds. There are also \"attributions\" which are lists of strings containing different references from the article. One clear issue with this dataset seems to be with the attributions field. There are many duplicates of sources just formatted in different ways. Additionally, there is also a decent amount of large sentence fragments which can make things more complicated. Another issue lies with the links field. There are many links for each article and some of them include insignificant and irrelevant links such as \"share this page\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1191ff-ba54-4ec8-95b8-e01bdebd51aa",
   "metadata": {},
   "source": [
    "all-coref-resolved.tar:\n",
    "This saves to my computer as a folder because it is in the Hugging Face Datasets format but it is a dataset with hundreds of thousands of articles with the following fields: article_url, target_timestamp_key (internal key), target_timestamp (when the article was captured), sort_criteria, wayback_url (URL of archived snapshot), wayback_timestamp (when archive snapshot was taken), \n",
    "method (of scraping), links(list of links in article), article_text (full article text), word_lists (words per sentence), sent_lists (sentences from the article), best_class (classification labels), coref_resolved_sents (the sentences but all the pronouns have been replaced with their associated nouns). The most clear issues to me are that a lot of the articles have no article_text and coref_resolved_sents. Another issue is that article_url is missing or incorrectly formatted for some which is problematic because this is what must be consistent with the other datasets in order to merge them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2814a29-9600-4f0c-a780-28409614a75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(9525) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/huggingface_hub-0.29.2-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: polars in /opt/anaconda3/lib/python3.12/site-packages (1.24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install polars\n",
    "import polars as pl\n",
    "from typing import Callable\n",
    "from datasets import load_from_disk\n",
    "from datasets import Dataset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e94ede0-022d-4422-be28-070acb1d626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_path = \"full-source-scored-data.jsonl\"\n",
    "csv_path = \"article-to-pr-mapper.csv\"\n",
    "resolved_folder = \"/Users/arsheyagourav/Desktop/VIP/A4/all-coref-resolved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9376b634-6e06-4178-9dcf-aac32a440599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable function to process large files in batches using Polars LazyFrame\n",
    "def process_batches_lazy(path, file_type, batch_size, process_fn):\n",
    "    if file_type == \"jsonl\":\n",
    "        full_df = pl.read_ndjson(path)\n",
    "    elif file_type == \"csv\":\n",
    "        full_df = pl.read_csv(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use 'jsonl' or 'csv'.\")\n",
    "\n",
    "    total_rows = full_df.height\n",
    "    for offset in range(0, total_rows, batch_size):\n",
    "        df = full_df.slice(offset, batch_size)\n",
    "        if df.is_empty():\n",
    "            break\n",
    "        lazy_df = df.lazy()\n",
    "        process_fn(lazy_df)\n",
    "\n",
    "\n",
    "def process_batches_from_hf_dataset(hf_dataset, batch_size, process_fn):\n",
    "    total_rows = len(hf_dataset)\n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch = hf_dataset.select(range(i, min(i + batch_size, total_rows)))\n",
    "        df = pl.DataFrame({k: batch[k] for k in batch.column_names})\n",
    "        lazy_df = df.lazy()\n",
    "        process_fn(lazy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72b07ec5-d893-406b-901e-efc9df6e7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check null and empty values in a lazy DataFrame\n",
    "total_null_counts = {}\n",
    "total_empty_counts = {}\n",
    "\n",
    "def check_nulls_and_empties_lazy(lazy_df, selected_cols=None):\n",
    "    schema = lazy_df.collect_schema()\n",
    "    if selected_cols:\n",
    "        schema = {k: v for k, v in schema.items() if k in selected_cols}\n",
    "\n",
    "    #print(f\"🧪 Checking columns: {list(schema.keys())}\")\n",
    "\n",
    "    # Null counts\n",
    "    null_exprs = [pl.col(col).is_null().sum().alias(col) for col in schema]\n",
    "    null_counts_df = lazy_df.select(null_exprs).collect()\n",
    "    null_counts = null_counts_df.to_dict(as_series=False)\n",
    "\n",
    "    # Empty string counts (only for Utf8 columns)\n",
    "    string_cols = [col for col, dtype in schema.items() if dtype == pl.Utf8]\n",
    "    if string_cols:\n",
    "        empty_exprs = [\n",
    "            pl.col(col).cast(str).str.strip_chars().eq(\"\").sum().alias(col)\n",
    "            for col in string_cols\n",
    "        ]\n",
    "        empty_counts_df = lazy_df.select(empty_exprs).collect()\n",
    "        empty_counts = empty_counts_df.to_dict(as_series=False)\n",
    "    else:\n",
    "        empty_counts = {}\n",
    "\n",
    "    return null_counts, empty_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbd4d0b0-57cc-4858-8fe2-d4a1f7e0e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to accumulate results across batches\n",
    "\n",
    "def run_lazy_checks(dataset_name, process_fn, batch_fn, *args, selected_cols=None, **kwargs):\n",
    "    print(f\"\\n--- Checking {dataset_name} dataset ---\")\n",
    "    total_null_counts = {}\n",
    "    total_empty_counts = {}\n",
    "\n",
    "    def accumulate_counts(lazy_df):\n",
    "        nonlocal total_null_counts, total_empty_counts\n",
    "        nulls, empties = check_nulls_and_empties_lazy(lazy_df, selected_cols)\n",
    "        #print(f\"✅ Nulls: {nulls}\\n✅ Empties: {empties}\")\n",
    "        for col, count in nulls.items():\n",
    "            total_null_counts[col] = total_null_counts.get(col, 0) + count[0]\n",
    "        for col, count in empties.items():\n",
    "            total_empty_counts[col] = total_empty_counts.get(col, 0) + count[0]\n",
    "\n",
    "    batch_fn(*args, process_fn=accumulate_counts, **kwargs)\n",
    "    print(\"\\n Total null values ({}):\".format(dataset_name), total_null_counts)\n",
    "    print(\" Total empty string values ({}):\".format(dataset_name), total_empty_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "48da78c1-601c-4494-b687-54509403e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for each dataset\n",
    "# Run for each dataset\n",
    "#run_lazy_checks(\"JSONL\", check_nulls_and_empties_lazy, process_batches_lazy, jsonl_path, \"jsonl\", 100_000)\n",
    "#run_lazy_checks(\"CSV\", check_nulls_and_empties_lazy, process_batches_lazy, csv_path, \"csv\", 100_000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b2f40ab-565e-422b-800c-e77e39160767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 and 4.3\n",
    "def run_source_counts(\n",
    "    dataset_label: str,\n",
    "    file_path: str,\n",
    "    file_type: str,\n",
    "    batch_size: int,\n",
    "    source_column: str\n",
    "):\n",
    "    print(f\"\\n📊 Counting '{source_column}' sources in {dataset_label} dataset\")\n",
    "\n",
    "    # Dictionary to accumulate counts across batches\n",
    "    source_counter = defaultdict(int)\n",
    "\n",
    "    def accumulate_counts(lazy_df):\n",
    "        try:\n",
    "            batch_counts = (\n",
    "                lazy_df\n",
    "                .group_by(source_column)\n",
    "                .agg(pl.len().alias(\"count\"))\n",
    "                .collect()\n",
    "            )\n",
    "\n",
    "            for row in batch_counts.iter_rows(named=True):\n",
    "                source = row[source_column]\n",
    "                count = row[\"count\"]\n",
    "                source_counter[source] += count\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping batch due to error: {e}\")\n",
    "\n",
    "    # Use the existing batch processor\n",
    "    process_batches_lazy(\n",
    "        path=file_path,\n",
    "        file_type=file_type,\n",
    "        batch_size=batch_size,\n",
    "        process_fn=accumulate_counts\n",
    "    )\n",
    "\n",
    "    # Display results as Polars DataFrame\n",
    "    result_df = (\n",
    "        pl.DataFrame({\n",
    "            source_column: list(source_counter.keys()),\n",
    "            \"total_count\": list(source_counter.values())\n",
    "        })\n",
    "        .sort(\"total_count\", descending=True)\n",
    "    )\n",
    "\n",
    "    print(f\"\\n📋 Total source counts in {dataset_label} dataset:\")\n",
    "    display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1503b5d2-e986-4d97-841c-3c6e8a7518f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Counting 'news_url_domain' sources in News Articles dataset\n",
      "\n",
      "📋 Total source counts in News Articles dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_686, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>news_url_domain</th><th>total_count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;businessinsider&quot;</td><td>80606</td></tr><tr><td>&quot;cbsnews&quot;</td><td>64546</td></tr><tr><td>&quot;cnbc&quot;</td><td>52562</td></tr><tr><td>&quot;pbs&quot;</td><td>44027</td></tr><tr><td>&quot;fortune&quot;</td><td>43387</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;postsouth&quot;</td><td>1</td></tr><tr><td>&quot;chicagomaroon&quot;</td><td>1</td></tr><tr><td>&quot;oneidadispatch&quot;</td><td>1</td></tr><tr><td>&quot;northcountrynow&quot;</td><td>1</td></tr><tr><td>&quot;shepherdexpress&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_686, 2)\n",
       "┌─────────────────┬─────────────┐\n",
       "│ news_url_domain ┆ total_count │\n",
       "│ ---             ┆ ---         │\n",
       "│ str             ┆ i64         │\n",
       "╞═════════════════╪═════════════╡\n",
       "│ businessinsider ┆ 80606       │\n",
       "│ cbsnews         ┆ 64546       │\n",
       "│ cnbc            ┆ 52562       │\n",
       "│ pbs             ┆ 44027       │\n",
       "│ fortune         ┆ 43387       │\n",
       "│ …               ┆ …           │\n",
       "│ postsouth       ┆ 1           │\n",
       "│ chicagomaroon   ┆ 1           │\n",
       "│ oneidadispatch  ┆ 1           │\n",
       "│ northcountrynow ┆ 1           │\n",
       "│ shepherdexpress ┆ 1           │\n",
       "└─────────────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_source_counts(\n",
    "    dataset_label=\"News Articles\",\n",
    "    file_path=csv_path,\n",
    "    file_type=\"csv\",\n",
    "    batch_size=100_000,\n",
    "    source_column=\"news_url_domain\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "597309e3-f7c7-4801-8a1d-73384af1c413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Counting 'company_name' sources in Press Releases dataset\n",
      "\n",
      "📋 Total source counts in Press Releases dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (595, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>company_name</th><th>total_count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;corporate&quot;</td><td>39823</td></tr><tr><td>&quot;newscorp&quot;</td><td>39391</td></tr><tr><td>&quot;ice&quot;</td><td>39382</td></tr><tr><td>&quot;go_factset&quot;</td><td>38991</td></tr><tr><td>&quot;usa_visa&quot;</td><td>33739</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;ir_archgroup&quot;</td><td>1</td></tr><tr><td>&quot;investors_essexapartmenthomes&quot;</td><td>1</td></tr><tr><td>&quot;investors_irco&quot;</td><td>1</td></tr><tr><td>&quot;newsroom_stanleyblackanddecker&quot;</td><td>1</td></tr><tr><td>&quot;ir_assurant&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (595, 2)\n",
       "┌────────────────────────────────┬─────────────┐\n",
       "│ company_name                   ┆ total_count │\n",
       "│ ---                            ┆ ---         │\n",
       "│ str                            ┆ i64         │\n",
       "╞════════════════════════════════╪═════════════╡\n",
       "│ corporate                      ┆ 39823       │\n",
       "│ newscorp                       ┆ 39391       │\n",
       "│ ice                            ┆ 39382       │\n",
       "│ go_factset                     ┆ 38991       │\n",
       "│ usa_visa                       ┆ 33739       │\n",
       "│ …                              ┆ …           │\n",
       "│ ir_archgroup                   ┆ 1           │\n",
       "│ investors_essexapartmenthomes  ┆ 1           │\n",
       "│ investors_irco                 ┆ 1           │\n",
       "│ newsroom_stanleyblackanddecker ┆ 1           │\n",
       "│ ir_assurant                    ┆ 1           │\n",
       "└────────────────────────────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_source_counts(\n",
    "    dataset_label=\"Press Releases\",\n",
    "    file_path=csv_path,\n",
    "    file_type=\"csv\",\n",
    "    batch_size=100_000,\n",
    "    source_column=\"company_name\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7dd6752a-4fd7-4abc-bcda-faec9ee75293",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ExprStringNameSpace' object has no attribute 'strip_chars_chars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# News Articles\u001b[39;00m\n\u001b[1;32m      2\u001b[0m news_df \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_ndjson(jsonl_path)\u001b[38;5;241m.\u001b[39mwith_columns([\n\u001b[0;32m----> 3\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle_url\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip_chars_chars()\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle_url_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Article-to-PR mapping\u001b[39;00m\n\u001b[1;32m      7\u001b[0m mapper_df \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\u001b[38;5;241m.\u001b[39mwith_columns([\n\u001b[1;32m      8\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip_chars_chars()\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle_url_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip_chars_chars()\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpress_release_url_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ExprStringNameSpace' object has no attribute 'strip_chars_chars'"
     ]
    }
   ],
   "source": [
    "# News Articles\n",
    "news_df = pl.read_ndjson(jsonl_path).with_columns([\n",
    "    pl.col(\"article_url\").str.strip_chars_chars().alias(\"article_url_clean\")\n",
    "])\n",
    "\n",
    "# Article-to-PR mapping\n",
    "mapper_df = pl.read_csv(csv_path).with_columns([\n",
    "    pl.col(\"URL\").str.strip_chars_chars().alias(\"article_url_clean\"),\n",
    "    pl.col(\"Target URL\").str.strip_chars_chars().alias(\"press_release_url_clean\")\n",
    "])\n",
    "\n",
    "# Coref-resolved dataset from HuggingFace\n",
    "resolved_df = pl.DataFrame({k: resolved_data[k] for k in resolved_data.column_names}).with_columns([\n",
    "    pl.col(\"article_url\").str.strip_chars_chars().alias(\"article_url_clean\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb390dc1-3cc0-47f9-9d53-e756686cff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔗 Merging news and mapper data...\")\n",
    "merged_1 = news_df.join(mapper_df, on=\"article_url_clean\", how=\"inner\")\n",
    "print(f\"✅ News + Mapper merged: {merged_1.shape[0]} rows\")\n",
    "\n",
    "print(\"🔗 Merging with coref-resolved...\")\n",
    "merged_final = merged_1.join(resolved_df, on=\"article_url_clean\", how=\"inner\")\n",
    "print(f\"✅ Fully merged dataset: {merged_final.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c398c6-699d-42d2-a4c7-93facde8b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many news articles didn't join with the mapper\n",
    "news_only = news_df.join(mapper_df, on=\"article_url_clean\", how=\"anti\")\n",
    "print(f\"⚠️ Articles not in mapper: {news_only.shape[0]}\")\n",
    "\n",
    "# How many mappings didn't match coref\n",
    "mapper_only = mapper_df.join(resolved_df, on=\"article_url_clean\", how=\"anti\")\n",
    "print(f\"⚠️ Mapper records not in coref-resolved: {mapper_only.shape[0]}\")\n",
    "\n",
    "# How many coref entries had no match in mapper/news\n",
    "coref_only = resolved_df.join(mapper_df, on=\"article_url_clean\", how=\"anti\")\n",
    "print(f\"⚠️ Coref-resolved records not in mapper: {coref_only.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f263be2d-f007-43ea-af18-c5659ccaa68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a1a649-a151-4db5-9b9b-77d732692585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: DatasetRelationships Pages: 1 -->\n",
       "<svg width=\"864pt\" height=\"263pt\"\n",
       " viewBox=\"0.00 0.00 864.00 262.83\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.827428 0.827428) rotate(0) translate(4 313.64)\">\n",
       "<title>DatasetRelationships</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-313.64 1040.2,-313.64 1040.2,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"117.91\" cy=\"-118.22\" rx=\"117.91\" ry=\"117.91\"/>\n",
       "<text text-anchor=\"middle\" x=\"117.91\" y=\"-119.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\">full&#45;source&#45;scored&#45;data.jsonl</text>\n",
       "<text text-anchor=\"middle\" x=\"117.91\" y=\"-106.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\">(Journalist Articles)</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"527.49\" cy=\"-200.22\" rx=\"109.42\" ry=\"109.42\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.49\" y=\"-201.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\">article&#45;to&#45;pr&#45;mapper.csv</text>\n",
       "<text text-anchor=\"middle\" x=\"527.49\" y=\"-188.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\">(Press Release Metadata)</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.38,-189.5C225.71,-196.74 239.71,-202.98 253.82,-207.22 302.95,-221.96 359.31,-222.98 408,-219.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"408.06,-222.75 417.72,-218.41 407.46,-215.77 408.06,-222.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"326.95\" y=\"-235.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">foreign key: article_url → URL</text>\n",
       "<text text-anchor=\"middle\" x=\"326.95\" y=\"-222.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(one&#45;to&#45;many)</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.41,-154.56C238.29,-156.62 246.15,-158.54 253.82,-160.22 317.85,-174.23 335.23,-169.62 400.07,-179.22 402.72,-179.61 405.39,-180.01 408.09,-180.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"407.37,-183.85 417.79,-181.91 408.44,-176.93 407.37,-183.85\"/>\n",
       "<text text-anchor=\"middle\" x=\"326.95\" y=\"-193.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">links → target_url</text>\n",
       "<text text-anchor=\"middle\" x=\"326.95\" y=\"-180.97\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(hyperlink match in article)</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M236.14,-119.7C299.07,-121.48 369.8,-125.35 400.07,-133.72 407.3,-135.72 414.58,-138.17 421.81,-140.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"420.35,-144.13 430.94,-144.65 422.99,-137.64 420.35,-144.13\"/>\n",
       "<text text-anchor=\"middle\" x=\"326.95\" y=\"-146.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">company_name mention in article</text>\n",
       "<text text-anchor=\"middle\" x=\"326.95\" y=\"-135.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(text match)</text>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"lightblue\" cx=\"942.68\" cy=\"-117.22\" rx=\"93.51\" ry=\"93.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"942.68\" y=\"-118.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\">all&#45;coref&#45;resolved</text>\n",
       "<text text-anchor=\"middle\" x=\"942.68\" y=\"-105.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\">(Coref&#45;Resolved Text)</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;C -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>A&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M232.07,-87.96C239.41,-86.28 246.71,-84.68 253.82,-83.22 505.2,-31.62 581.03,-17.9 831.17,-75.22 835.73,-76.26 840.35,-77.45 844.99,-78.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"843.78,-82.05 854.37,-81.55 845.78,-75.34 843.78,-82.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.49\" y=\"-65.15\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">foreign key: article_url → article_url</text>\n",
       "<text text-anchor=\"middle\" x=\"527.49\" y=\"-52.4\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(one&#45;to&#45;one)</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;A -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>B&#45;&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446.85,-125.72C432.23,-115.78 416.4,-107.09 400.07,-101.47 350.85,-84.52 293.95,-84.57 244.27,-90.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"244.11,-86.89 234.63,-91.63 244.99,-93.84 244.11,-86.89\"/>\n",
       "<text text-anchor=\"middle\" x=\"326.95\" y=\"-104.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">reverse: URL → article_url</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;C -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>B&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M635.9,-217.18C695.01,-222.44 768.8,-222.23 831.17,-201.22 842.16,-197.52 852.92,-192.24 863.16,-186.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"864.95,-189.11 871.52,-180.8 861.2,-183.2 864.95,-189.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"743.04\" y=\"-223.29\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">metadata join: article_url → article_url</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;A -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>C&#45;&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M869.48,-58.43C857.27,-50.84 844.28,-44.05 831.17,-39.22 658.72,24.29 601.1,-5.03 418.07,-21.47 344.18,-28.11 324.24,-27.88 253.82,-51.22 246.9,-53.51 239.88,-56.1 232.88,-58.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231.94,-55.49 224.04,-62.54 234.61,-61.96 231.94,-55.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.49\" y=\"-24.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">reverse: article_url → article_url</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;B -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>C&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M857.53,-156.82C848.76,-160.03 839.86,-162.91 831.17,-165.22 755,-185.42 733.19,-175.32 654.92,-184.47 652.56,-184.74 650.18,-185.02 647.77,-185.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"647.44,-181.82 637.92,-186.48 648.26,-188.77 647.44,-181.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"743.04\" y=\"-187.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">reverse: resolved text → press release</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;B -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>C&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M848.89,-119.78C779.31,-122.43 690.25,-127.59 654.92,-137.22 648.17,-139.06 641.35,-141.27 634.56,-143.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"633.41,-140.44 625.35,-147.31 635.94,-146.97 633.41,-140.44\"/>\n",
       "<text text-anchor=\"middle\" x=\"743.04\" y=\"-151.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">links → target_url</text>\n",
       "<text text-anchor=\"middle\" x=\"743.04\" y=\"-138.97\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(hyperlink in resolved text)</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;B -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>C&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M852.51,-90.93C794.55,-78.39 718.27,-70.59 654.92,-93.72 640.6,-98.94 626.78,-106.59 613.87,-115.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"611.96,-112.48 605.87,-121.16 616.04,-118.17 611.96,-112.48\"/>\n",
       "<text text-anchor=\"middle\" x=\"743.04\" y=\"-106.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">company_name mention in resolved text</text>\n",
       "<text text-anchor=\"middle\" x=\"743.04\" y=\"-95.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(text match)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1320b2870>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the graph\n",
    "g = Digraph(\"DatasetRelationships\", format=\"svg\")\n",
    "g.attr(rankdir=\"LR\", size=\"12,8\")\n",
    "\n",
    "# Dataset nodes\n",
    "g.attr(\"node\", shape=\"circle\", style=\"filled\", color=\"lightblue\", fontname=\"Helvetica\", fontsize=\"12\")\n",
    "g.node(\"A\", \"full-source-scored-data.jsonl\\n(Journalist Articles)\")\n",
    "g.node(\"B\", \"article-to-pr-mapper.csv\\n(Press Release Metadata)\")\n",
    "g.node(\"C\", \"all-coref-resolved\\n(Coref-Resolved Text)\")\n",
    "\n",
    "# Edge formatting\n",
    "g.attr(\"edge\", fontname=\"Helvetica\", fontsize=\"10\")\n",
    "\n",
    "# -- Explicit joins --\n",
    "g.edge(\"A\", \"B\", label=\"foreign key: article_url → URL\\n(one-to-many)\")\n",
    "g.edge(\"B\", \"A\", label=\"reverse: URL → article_url\")\n",
    "\n",
    "g.edge(\"A\", \"C\", label=\"foreign key: article_url → article_url\\n(one-to-one)\")\n",
    "g.edge(\"C\", \"A\", label=\"reverse: article_url → article_url\")\n",
    "\n",
    "g.edge(\"B\", \"C\", label=\"metadata join: article_url → article_url\")\n",
    "g.edge(\"C\", \"B\", label=\"reverse: resolved text → press release\")\n",
    "\n",
    "# -- Implicit relationships --\n",
    "g.edge(\"A\", \"B\", label=\"links → target_url\\n(hyperlink match in article)\")\n",
    "g.edge(\"C\", \"B\", label=\"links → target_url\\n(hyperlink in resolved text)\")\n",
    "\n",
    "g.edge(\"A\", \"B\", label=\"company_name mention in article\\n(text match)\")\n",
    "g.edge(\"C\", \"B\", label=\"company_name mention in resolved text\\n(text match)\")\n",
    "\n",
    "# Display in notebook\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139120b7-6530-4eca-8b90-055c21c0f6ea",
   "metadata": {},
   "source": [
    "caption here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa21667-070c-4eff-ab99-94c9cdbe14d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a4672-d009-4917-accb-a0fe9801f97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c27013-1007-404f-b155-5f1c3c751f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
